{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import lpips\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# wandb\n",
    "import wandb\n",
    "\n",
    "# images\n",
    "from skimage import io\n",
    "from skimage import transform\n",
    "\n",
    "# metrics\n",
    "import torchmetrics\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/e/e0425222/CS4243/\")\n",
    "from utils.dataset_utils.AnimalDataset import AnimalDataset\n",
    "from utils.train_utils.train_utils import visualize_results, sample_batch\n",
    "from utils.train_utils.model_utils import Conv2dBlock, GatedConv2dBlock, GatedUpConv2dBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, activation):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # same -> downsample -> same -> downsample\n",
    "        self.conv0 = GatedConv2dBlock(input_dim, hidden_dim, kernel_size = 3, stride = 1, padding = 1, dilation = 1, activation = activation)\n",
    "        self.conv1 = GatedConv2dBlock(hidden_dim, hidden_dim, kernel_size = 3, stride = 2, padding = 1, dilation = 1, activation = activation)\n",
    "        self.conv2 = GatedConv2dBlock(hidden_dim, hidden_dim, kernel_size = 3, stride = 1, padding = 1, dilation = 1, activation = activation)\n",
    "        self.conv3 = GatedConv2dBlock(hidden_dim, hidden_dim, kernel_size = 3, stride = 2, padding = 1, dilation = 1, activation = activation)\n",
    "\n",
    "        # 2 x same conv\n",
    "        self.conv4 = GatedConv2dBlock(hidden_dim, hidden_dim, kernel_size = 3, stride = 1, padding = 1, dilation = 1, activation = activation)\n",
    "        self.conv5 = GatedConv2dBlock(hidden_dim, hidden_dim, kernel_size = 3, stride = 1, padding = 1, dilation = 1, activation = activation)\n",
    "\n",
    "        # 4 x dilated conv\n",
    "        self.conv6 = GatedConv2dBlock(hidden_dim, hidden_dim, kernel_size = 3, stride = 1, padding = 2, dilation = 2, activation = activation)\n",
    "        self.conv7 = GatedConv2dBlock(hidden_dim, hidden_dim, kernel_size = 3, stride = 1, padding = 4, dilation = 4, activation = activation)\n",
    "        self.conv8 = GatedConv2dBlock(hidden_dim, hidden_dim, kernel_size = 3, stride = 1, padding = 8, dilation = 8, activation = activation)\n",
    "        self.conv9 = GatedConv2dBlock(hidden_dim, hidden_dim, kernel_size = 3, stride = 1, padding = 16, dilation = 16, activation = activation)\n",
    "\n",
    "        # 2 x same conv\n",
    "        self.conv10 = GatedConv2dBlock(hidden_dim, hidden_dim, kernel_size = 3, stride = 1, padding = 1, dilation = 1, activation = activation)\n",
    "        self.conv11 = GatedConv2dBlock(hidden_dim, hidden_dim, kernel_size = 3, stride = 1, padding = 1, dilation = 1, activation = activation)\n",
    "\n",
    "        # upsample -> same -> upsample -> same\n",
    "        self.conv12 = GatedUpConv2dBlock(hidden_dim, hidden_dim, scale_factor = (2,2), kernel_size = 3, stride = 1, padding = 1, dilation = 1)\n",
    "        self.conv13 = GatedConv2dBlock(hidden_dim, hidden_dim, kernel_size = 3, stride = 1, padding = 1, dilation = 1, activation = activation)\n",
    "        self.conv14 = GatedUpConv2dBlock(hidden_dim, hidden_dim, scale_factor = (2,2), kernel_size = 3, stride = 1, padding = 1, dilation = 1)\n",
    "        self.conv15 = GatedConv2dBlock(hidden_dim, hidden_dim, kernel_size = 3, stride = 1, padding = 1, dilation = 1, activation = activation)\n",
    "\n",
    "        # final\n",
    "        self.final = nn.Conv2d(hidden_dim, output_dim, kernel_size = 3, stride = 1, padding = 'same')\n",
    "\n",
    "        # for contrastive learning, 1x1 conv to compress feature map into 1 channel\n",
    "        self.conv_feature = nn.Conv2d(hidden_dim, 1, kernel_size = 1, stride = 1, padding = 'same')\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "\n",
    "        x = self.conv0(input_tensor)\n",
    "        \n",
    "        # downsample\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        # middle layers\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "\n",
    "        # dilated conv with residual skips\n",
    "        x = self.conv6(x) + x\n",
    "        x = self.conv7(x) + x\n",
    "        x = self.conv8(x) + x\n",
    "        x = self.conv9(x) + x\n",
    "\n",
    "        # extract for contrastive loss\n",
    "        x_feature = self.conv_feature(x)\n",
    "\n",
    "        # middle layers\n",
    "        x = self.conv10(x)\n",
    "        x = self.conv11(x)\n",
    "\n",
    "        # upsample\n",
    "        x = self.conv12(x)\n",
    "        x = self.conv13(x)\n",
    "        x = self.conv14(x)\n",
    "        x = self.conv15(x)\n",
    "        \n",
    "        # final\n",
    "        x = self.final(x)\n",
    "\n",
    "        return x, x_feature\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, input_shape, activation):\n",
    "\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # 5 layers down\n",
    "        self.conv0 = Conv2dBlock(input_dim, hidden_dim, kernel_size = 3, stride = 2, padding = 1, dilation = 1, activation = activation, partial = False)\n",
    "        self.conv1 = Conv2dBlock(hidden_dim, hidden_dim, kernel_size = 3, stride = 2, padding = 1, dilation = 1, activation = activation, partial = False)\n",
    "        self.conv2 = Conv2dBlock(hidden_dim, hidden_dim, kernel_size = 3, stride = 2, padding = 1, dilation = 1, activation = activation, partial = False)\n",
    "        self.conv3 = Conv2dBlock(hidden_dim, hidden_dim, kernel_size = 3, stride = 2, padding = 1, dilation = 1, activation = activation, partial = False)\n",
    "        self.conv4 = Conv2dBlock(hidden_dim, hidden_dim, kernel_size = 3, stride = 2, padding = 1, dilation = 1, activation = activation, partial = False)\n",
    "\n",
    "        # linear to predict classes\n",
    "        LATENT_H = input_shape//(2**5)\n",
    "        self.linear = nn.Linear(LATENT_H**2 * hidden_dim, 1)\n",
    "\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        \n",
    "        x = self.conv0(input_tensor)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "\n",
    "        # scores\n",
    "        x = torch.flatten(x, start_dim = 1)\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9319ae1760e4d45d7d7c835d46b6f1010677823a105cd126e5ae41ed73f571cc"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
